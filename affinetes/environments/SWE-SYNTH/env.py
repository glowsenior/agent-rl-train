"""
SWE-SYNTH Environment

Supports two modes:
1. evaluate() - One-shot evaluation with internal fixer agent
2. reset/step/stop - OpenEnv training interface for external control

Flow:
    task_id → load from R2 → fixer repair → verify
"""

import os
import re
import json
import time
import uuid
import asyncio
import tempfile
import subprocess
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List
from datasets import load_dataset

import yaml
from jinja2 import StrictUndefined, Template

# Import cache module
from cache import TwoLevelCache

# Import fixer agent abstraction
from fixer import create_fixer_agent, FixerConfig, AgentType

# Import OpenEnv response type
from affinetes.core.openenv import OpenEnvResponse

# Import shared utilities
from utils import SANITIZE_GIT_SCRIPT, DIFF_EXTENSIONS


# Timeout constants (in seconds)
DOCKER_PULL_TIMEOUT = 300
FIXER_TIMEOUT = 1800
VERIFY_FIX_TIMEOUT = 1800

# OpenEnv constants
DEFAULT_STEP_LIMIT = 100
DEFAULT_COMMAND_TIMEOUT = 300
SUBMIT_MARKER = "COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT"
ACTION_REGEX = r"```bash\s*\n(.*?)\n```"


@dataclass
class EpisodeState:
    """Training episode state for SWE-SYNTH"""
    episode_id: str
    task_id: int
    seed: int
    bug_instance: Dict[str, Any]

    # Docker environment
    container_id: str
    docker_image: str

    # Agent state
    messages: List[Dict[str, Any]] = field(default_factory=list)
    step_count: int = 0
    done: bool = False
    truncated: bool = False
    submitted_patch: Optional[str] = None

    # Configuration
    step_limit: int = DEFAULT_STEP_LIMIT
    command_timeout: int = DEFAULT_COMMAND_TIMEOUT

    # Timestamps
    start_time: float = field(default_factory=time.time)


def get_dockerhub_image_uri(uid: str, dockerhub_username: str, repo_name: str) -> str:
    """Generate Docker Hub image URI matching SWE-bench naming scheme."""
    repo_base, repo_name_only = repo_name.lower().split("/")
    hsh = uid.replace("instance_", "")

    if uid == "instance_element-hq__element-web-ec0f940ef0e8e3b61078f145f34dc40d1938e6c5-vnan":
        repo_name_only = 'element-web'
    elif 'element-hq' in repo_name.lower() and 'element-web' in repo_name.lower():
        repo_name_only = 'element'
        if hsh.endswith('-vnan'):
            hsh = hsh[:-5]
    elif hsh.endswith('-vnan'):
        hsh = hsh[:-5]

    tag = f"{repo_base}.{repo_name_only}-{hsh}"
    if len(tag) > 128:
        tag = tag[:128]

    return f"{dockerhub_username}/sweap-images:{tag}"


class SynthActor:
    """
    SWE-SYNTH evaluation actor (fixer only).

    Evaluates fixer models on pre-generated tasks from R2.
    Tasks must be generated by the breaker service before evaluation.
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        cache_dir: str = "/tmp/swe-synth-cache",
        dockerhub_username: str = "jefzda",
        dockerfiles_dir: str = "/app/ridges/dockerfiles",
        run_scripts_dir: str = "/app/ridges/run_scripts",
        # R2 read-only cache (public URL, no auth needed)
        r2_public_read_url: str = "https://pub-4b43a94ed07d4ac38fae3f4cb5070d6c.r2.dev",
        r2_prefix: str = "bugs",
    ):
        """
        Initialize SWE-SYNTH evaluation actor.

        Args:
            api_key: API key for LLM (optional, can also use environment variables)
            cache_dir: Directory for local cache
            dockerhub_username: Docker Hub username for images
            dockerfiles_dir: Path to SWE-bench dockerfiles
            run_scripts_dir: Path to SWE-bench run scripts
            r2_public_read_url: R2 public CDN URL for reading tasks
            r2_prefix: Prefix for R2 cache keys
        """
        self.api_key = api_key or os.getenv("CHUTES_API_KEY")
        self.dockerhub_username = dockerhub_username
        self.dockerfiles_dir = dockerfiles_dir
        self.run_scripts_dir = run_scripts_dir

        # Initialize two-level cache (read-only)
        self.cache = TwoLevelCache(
            local_cache_dir=cache_dir,
            r2_public_read_url=r2_public_read_url,
            r2_prefix=r2_prefix,
        )

        # Load SWE-bench Pro dataset (for verification)
        print("Loading SWE-bench Pro dataset...")
        dataset = load_dataset("ScaleAI/SWE-bench_Pro", split="test")
        sorted_instances = sorted(dataset, key=lambda x: x["instance_id"])
        self.swe_instances = {idx: inst for idx, inst in enumerate(sorted_instances)}
        print(f"Loaded {len(self.swe_instances)} SWE-bench Pro instances")

        # Cleanup stale containers from previous runs
        self._cleanup_stale_containers()

        # OpenEnv: episode states for concurrent episodes
        self._episodes: Dict[str, EpisodeState] = {}

        # OpenEnv: load agent config from config.yaml
        self._agent_config = self._load_agent_config()

    def _cleanup_stale_containers(self, min_age_minutes: int = 2):
        """
        Clean up stale ridge-proxy and ridges-sandbox containers from previous runs.

        Args:
            min_age_minutes: Only remove containers older than this many minutes (default: 2)
        """
        try:
            cleaned_count = 0
            for name_filter in ["ridge-proxy-", "ridges-sandbox-", "swe-synth-fixer-", "swe-synth-openenv-", "minisweagent-"]:
                # Get container IDs and creation times
                result = subprocess.run(
                    ["docker", "ps", "-a", "--filter", f"name={name_filter}",
                     "--format", "{{.ID}} {{.CreatedAt}}"],
                    capture_output=True, text=True, timeout=30
                )
                if not result.stdout.strip():
                    continue

                from datetime import datetime, timezone
                now = datetime.now(timezone.utc)

                for line in result.stdout.strip().split('\n'):
                    if not line.strip():
                        continue
                    parts = line.split(' ', 1)
                    if len(parts) < 2:
                        continue
                    cid, created_str = parts[0], parts[1]

                    # Parse creation time (format: "2026-01-29 10:00:00 +0000 UTC")
                    try:
                        # Remove timezone name suffix if present
                        created_str = created_str.rsplit(' ', 1)[0] if 'UTC' in created_str else created_str
                        created = datetime.strptime(created_str.strip(), "%Y-%m-%d %H:%M:%S %z")
                        age_minutes = (now - created).total_seconds() / 60

                        if age_minutes >= min_age_minutes:
                            subprocess.run(
                                ["docker", "rm", "-f", cid],
                                capture_output=True, timeout=30
                            )
                            cleaned_count += 1
                    except (ValueError, TypeError):
                        # If we can't parse the time, skip this container
                        continue

            if cleaned_count > 0:
                print(f"[SWE-SYNTH] Cleaned up {cleaned_count} stale containers (older than {min_age_minutes} min)")

        except Exception as e:
            print(f"[SWE-SYNTH] Warning: Failed to cleanup stale containers: {e}")

    def _load_task(self, task_id: int) -> Dict[str, Any]:
        """
        Load pre-generated task from R2.

        Args:
            task_id: Task ID to load

        Returns:
            Task data dict (bug_instance)

        Raises:
            ValueError: If task not found in R2
        """
        bug_instance = self.cache.load(task_id)
        if bug_instance is None:
            raise ValueError(
                f"Task {task_id} not found. "
                f"Tasks must be pre-generated by the breaker service."
            )
        return bug_instance

    def _load_instance_script(self, instance_id: str, script_name: str) -> Optional[str]:
        """Load instance-specific script."""
        script_path = Path(self.run_scripts_dir) / instance_id / script_name
        if not script_path.exists():
            return None
        with open(script_path, 'r') as f:
            return f.read()

    def _load_dockerfile(self, instance_id: str, dockerfile_type: str) -> str:
        """Load Dockerfile content."""
        dockerfile_path = f"{self.dockerfiles_dir}/{dockerfile_type}_dockerfile/{instance_id}/Dockerfile"
        with open(dockerfile_path) as fp:
            return fp.read()

    def _extract_env_commands(self, base_dockerfile: str, instance_dockerfile: str) -> str:
        """Extract ENV commands from Dockerfiles."""
        env_cmds = []
        for dockerfile_content in [base_dockerfile, instance_dockerfile]:
            for line in dockerfile_content.split("\n"):
                line = line.strip()
                if line.startswith("ENV"):
                    env_cmd = line.replace("ENV", "export", 1)
                    env_cmds.append(env_cmd)
        return "\n".join(env_cmds)

    def _verify_fix(
        self,
        bug_instance: Dict[str, Any],
        fix_patch: str,
    ) -> tuple[float, Dict[str, Any]]:
        """
        Verify if the fix patch resolves the bug.

        Returns:
            Tuple of (score, test_stats)
        """
        if not fix_patch or not fix_patch.strip():
            return 0.0, {"error": "no patch"}

        try:
            source = bug_instance["source"]
            instance_id = source["swe_instance_id"]
            repo = source["repo"]
            base_commit = source["base_commit"]

            # Get original instance for test info
            swe_instance = None
            for inst in self.swe_instances.values():
                if inst["instance_id"] == instance_id:
                    swe_instance = inst
                    break

            if not swe_instance:
                return 0.0, {"error": f"Instance not found: {instance_id}"}

            # Get test requirements
            fail_to_pass = swe_instance.get("FAIL_TO_PASS", swe_instance.get("fail_to_pass", "[]"))
            pass_to_pass = swe_instance.get("PASS_TO_PASS", swe_instance.get("pass_to_pass", "[]"))

            if isinstance(fail_to_pass, str):
                try:
                    fail_to_pass = eval(fail_to_pass)
                except:
                    fail_to_pass = []
            if isinstance(pass_to_pass, str):
                try:
                    pass_to_pass = eval(pass_to_pass)
                except:
                    pass_to_pass = []

            f2p = set(fail_to_pass)
            p2p = set(pass_to_pass)
            required_tests = f2p | p2p

            if not required_tests:
                return 0.0, {"error": "No required tests"}

            # Load scripts
            run_script = self._load_instance_script(instance_id, "run_script.sh")
            parser_script = self._load_instance_script(instance_id, "parser.py")

            if not run_script or not parser_script:
                return 0.0, {"error": "Missing scripts"}

            # Build verification script
            try:
                base_dockerfile = self._load_dockerfile(instance_id, "base")
                instance_dockerfile = self._load_dockerfile(instance_id, "instance")
                env_cmds = self._extract_env_commands(base_dockerfile, instance_dockerfile)
            except Exception:
                env_cmds = ""

            before_repo_set_cmd = swe_instance.get("before_repo_set_cmd", "").strip()
            if before_repo_set_cmd:
                before_repo_set_cmd = before_repo_set_cmd.split("\n")[-1]

            selected_test_files = swe_instance.get("selected_test_files_to_run", "[]")
            if isinstance(selected_test_files, str):
                try:
                    selected_test_files = eval(selected_test_files)
                except:
                    selected_test_files = []
            test_files_str = ",".join(selected_test_files) if selected_test_files else ""

            import base64

            # Get patches
            gold_patch = bug_instance["original"]["gold_patch"]
            bug_patch = bug_instance["bug"]["patch"]

            # Flow: base_commit → gold_patch → bug_patch → fix_patch
            entryscript = f"""
{env_cmds}
cd /app
git reset --hard {base_commit}
git checkout {base_commit}

# Step 1: Apply gold_patch to get correct code (all tests pass)
git apply -v /workspace/gold_patch.diff

# Step 2: Apply bug_patch to inject the bug (target tests should fail)
git apply -v /workspace/bug_patch.diff || true

# Step 3: Apply fix_patch from Fixer (should restore correctness)
git apply -v /workspace/fix_patch.diff
{before_repo_set_cmd}

# Run tests
bash /workspace/run_script.sh {test_files_str} > /workspace/stdout.log 2> /workspace/stderr.log
python /workspace/parser.py /workspace/stdout.log /workspace/stderr.log /workspace/output.json
"""

            gold_patch_b64 = base64.b64encode(gold_patch.encode('utf-8')).decode('ascii')
            bug_patch_b64 = base64.b64encode(bug_patch.encode('utf-8')).decode('ascii')
            fix_patch_b64 = base64.b64encode(fix_patch.encode('utf-8')).decode('ascii')
            run_script_b64 = base64.b64encode(run_script.encode('utf-8')).decode('ascii')
            parser_script_b64 = base64.b64encode(parser_script.encode('utf-8')).decode('ascii')
            entryscript_b64 = base64.b64encode(entryscript.encode('utf-8')).decode('ascii')

            full_script = f"""#!/bin/bash
mkdir -p /workspace
echo "{gold_patch_b64}" | base64 -d > /workspace/gold_patch.diff
echo "{bug_patch_b64}" | base64 -d > /workspace/bug_patch.diff
echo "{fix_patch_b64}" | base64 -d > /workspace/fix_patch.diff
echo "{run_script_b64}" | base64 -d > /workspace/run_script.sh
echo "{parser_script_b64}" | base64 -d > /workspace/parser.py
echo "{entryscript_b64}" | base64 -d > /workspace/entryscript.sh
chmod +x /workspace/run_script.sh /workspace/entryscript.sh
bash /workspace/entryscript.sh
if [ -f /workspace/output.json ]; then
    echo "===SWESYNTH_OUTPUT_BEGIN==="
    cat /workspace/output.json
    echo "===SWESYNTH_OUTPUT_END==="
fi
"""

            # Get Docker image and run
            image = get_dockerhub_image_uri(instance_id, self.dockerhub_username, repo)

            print(f"Pulling image for verify_fix: {image}")
            subprocess.run(
                ["docker", "pull", image],
                check=False, capture_output=True, timeout=DOCKER_PULL_TIMEOUT
            )

            print(f"Running verification container (timeout={VERIFY_FIX_TIMEOUT}s)...")
            result = subprocess.run(
                ["docker", "run", "--rm", "-i", "--entrypoint", "/bin/bash", image],
                input=full_script,
                capture_output=True,
                timeout=VERIFY_FIX_TIMEOUT,
                text=True
            )
            print("Verification container completed.")

            stdout = result.stdout

            begin_marker = "===SWESYNTH_OUTPUT_BEGIN==="
            end_marker = "===SWESYNTH_OUTPUT_END==="

            if begin_marker not in stdout or end_marker not in stdout:
                return 0.0, {"error": "No output markers", "stderr": result.stderr[:500]}

            json_start = stdout.index(begin_marker) + len(begin_marker)
            json_end = stdout.index(end_marker)
            json_str = stdout[json_start:json_end].strip()

            output = json.loads(json_str)

            passed_tests = {x["name"] for x in output["tests"] if x["status"] == "PASSED"}

            # Get target tests from bug_instance (tests that Breaker tried to break)
            target_tests = set(bug_instance["bug"].get("target_tests", []))

            # Success criteria: target_tests must pass (bug was fixed)
            # Also check all tests for completeness
            all_required = f2p | p2p
            target_passed = target_tests <= passed_tests
            all_passed = all_required <= passed_tests

            target_passed_count = len(target_tests & passed_tests)
            total_target = len(target_tests)
            all_passed_count = len(all_required & passed_tests)
            total_all = len(all_required)

            test_stats = {
                "target_tests": list(target_tests),
                "target_result": f"{target_passed_count}/{total_target}",
                "all_result": f"{all_passed_count}/{total_all}",
                "target_passed": target_passed,
                "all_passed": all_passed,
            }

            # Score: 1 if all tests pass, 0 otherwise
            if all_passed:
                return 1.0, test_stats
            else:
                # Record which tests failed
                test_stats["missing_tests"] = list(all_required - passed_tests)
                return 0.0, test_stats

        except subprocess.TimeoutExpired:
            return 0.0, {"error": "timeout"}
        except Exception as e:
            import traceback
            return 0.0, {"error": traceback.format_exc()}

    # ========== OpenEnv Helper Methods ==========

    def _load_agent_config(self) -> Dict[str, Any]:
        """Load agent configuration from config.yaml"""
        config_path = Path(__file__).parent / "config.yaml"
        if config_path.exists():
            with open(config_path, "r") as f:
                config = yaml.safe_load(f)
                return config.get("agent", {})
        return {}

    def _render_template(self, template: str, **kwargs) -> str:
        """Render a Jinja2 template with the given variables"""
        return Template(template, undefined=StrictUndefined).render(**kwargs)

    def _info(
        self,
        ep: Optional[EpisodeState] = None,
        *,
        error: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Build info dictionary for OpenEnv response"""
        info: Dict[str, Any] = {
            "task_id": ep.task_id if ep else None,
            "seed": ep.seed if ep else None,
            "step_count": ep.step_count if ep else 0,
            "swe_instance_id": ep.bug_instance["source"]["swe_instance_id"] if ep else None,
            "bug_types": ep.bug_instance.get("bug", {}).get("bug_types", []) if ep else [],
        }
        if error:
            info["error"] = error
        return info

    def _start_container(self, docker_image: str, container_name: str) -> str:
        """Start a Docker container and return the container ID"""
        # Pull image first
        print(f"[SWE-SYNTH] Pulling image: {docker_image}")
        subprocess.run(
            ["docker", "pull", docker_image],
            capture_output=True,
            timeout=DOCKER_PULL_TIMEOUT,
        )

        # Start container with sleep to keep it running
        cmd = [
            "docker", "run", "-d",
            "--name", container_name,
            "-w", "/app",
            "--rm",
            "--entrypoint", "",
            docker_image,
            "sleep", "7200",  # 2 hours max
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
        if result.returncode != 0:
            raise RuntimeError(f"Failed to start container: {result.stderr}")

        container_id = result.stdout.strip()
        print(f"[SWE-SYNTH] Started container {container_name} ({container_id[:12]})")
        return container_id

    def _execute_in_container(
        self,
        container_id: str,
        command: str,
        timeout: int = DEFAULT_COMMAND_TIMEOUT
    ) -> Dict[str, Any]:
        """Execute a command in a Docker container"""
        cmd = ["docker", "exec", "-w", "/app", container_id, "bash", "-lc", command]
        try:
            result = subprocess.run(
                cmd,
                text=True,
                timeout=timeout,
                encoding="utf-8",
                errors="replace",
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
            )
            return {"output": result.stdout, "returncode": result.returncode}
        except subprocess.TimeoutExpired as e:
            output = e.output.decode("utf-8", errors="replace") if e.output else ""
            return {"output": output, "returncode": -1, "timeout": True}

    def _apply_patches_to_container(
        self,
        container_id: str,
        gold_patch: Optional[str],
        bug_patch: Optional[str],
    ) -> bool:
        """Apply gold_patch and bug_patch inside container"""
        patch_names = ["gold_patch", "bug_patch"]

        for idx, patch in enumerate([gold_patch, bug_patch]):
            if patch:
                with tempfile.NamedTemporaryFile(mode='w', suffix='.diff', delete=False) as f:
                    f.write(patch)
                    temp_path = f.name
                try:
                    # Copy patch to container
                    subprocess.run(
                        ["docker", "cp", temp_path, f"{container_id}:/tmp/patch_{idx}.diff"],
                        check=True, capture_output=True, timeout=30
                    )
                    # Apply patch
                    result = self._execute_in_container(
                        container_id,
                        f"cd /app && git apply -v /tmp/patch_{idx}.diff 2>&1",
                        timeout=120
                    )
                    result_str = result.get("output", "")
                    result_lower = result_str.lower()
                    if "error" in result_lower or "rejected" in result_lower or "patch failed" in result_lower:
                        print(f"[SWE-SYNTH] Warning: {patch_names[idx]} may have failed: {result_str[:500]}")
                    else:
                        print(f"[SWE-SYNTH] {patch_names[idx]} applied successfully")
                finally:
                    os.unlink(temp_path)

        # Sanitize git history to prevent cheating
        self._sanitize_git_history_in_container(container_id)
        return True

    def _sanitize_git_history_in_container(self, container_id: str) -> bool:
        """Remove git history to prevent cheating"""
        result = self._execute_in_container(container_id, SANITIZE_GIT_SCRIPT, timeout=60)
        print(f"[SWE-SYNTH] Git history sanitization: {result.get('output', '')[:200]}")
        return True

    def _parse_action(self, action: str) -> Optional[str]:
        """Parse bash command from action string (same as minisweagent)"""
        # Strip thinking tags if present
        if "</think>" in action:
            action = action.split("</think>")[-1].strip()

        actions = re.findall(ACTION_REGEX, action, re.DOTALL)
        if len(actions) == 1:
            return actions[0].strip()
        return None

    def _extract_diff_from_container(self, container_id: str) -> str:
        """Extract code diff from container"""
        result = self._execute_in_container(
            container_id,
            f"cd /app && git add -A && git diff --cached -- {DIFF_EXTENSIONS}",
            timeout=60
        )
        diff = result.get("output", "").lstrip()
        diff = diff.rstrip('\n') + '\n' if diff else ""
        return diff

    def _stop_container(self, container_id: str):
        """Stop and remove a Docker container"""
        try:
            subprocess.Popen(
                f"(timeout 60 docker stop {container_id} || docker rm -f {container_id}) >/dev/null 2>&1 &",
                shell=True
            )
        except Exception as e:
            print(f"[SWE-SYNTH] Warning: Failed to stop container: {e}")

    # ========== OpenEnv Training Interface ==========

    async def reset(
        self,
        task_id: int,
        seed: Optional[int] = None,
        step_limit: int = DEFAULT_STEP_LIMIT,
        command_timeout: int = DEFAULT_COMMAND_TIMEOUT,
    ) -> OpenEnvResponse:
        """
        Reset environment and start a new episode.

        Args:
            task_id: Task identifier (must exist in R2)
            seed: Random seed for reproducibility
            step_limit: Maximum number of steps before truncation
            command_timeout: Timeout for each command execution

        Returns:
            OpenEnvResponse with initial observation (system + instance prompt)
        """
        import random
        resolved_seed = seed if seed is not None else random.randint(0, 2**32 - 1)

        try:
            # Load task from R2
            bug_instance = self._load_task(task_id)
            source = bug_instance["source"]
            instance_id = source["swe_instance_id"]
            repo = source["repo"]
            problem_statement = bug_instance["bug"]["problem_statement"]

            print(f"[SWE-SYNTH] Loaded task {task_id}: {instance_id}")

            # Get Docker image
            docker_image = get_dockerhub_image_uri(instance_id, self.dockerhub_username, repo)

            # Generate episode ID and container name
            episode_id = uuid.uuid4().hex
            container_name = f"swe-synth-openenv-{episode_id[:8]}"

            # Start container
            container_id = self._start_container(docker_image, container_name)

            # Apply patches
            gold_patch = bug_instance["original"].get("gold_patch", "")
            bug_patch = bug_instance["bug"].get("patch", "")
            self._apply_patches_to_container(container_id, gold_patch, bug_patch)

            # Create episode state
            ep = EpisodeState(
                episode_id=episode_id,
                task_id=task_id,
                seed=resolved_seed,
                bug_instance=bug_instance,
                container_id=container_id,
                docker_image=docker_image,
                step_limit=step_limit,
                command_timeout=command_timeout,
            )

            # Render initial prompts (same as minisweagent)
            system_template = self._agent_config.get("system_template", "")
            instance_template = self._agent_config.get("instance_template", "")

            system_msg = self._render_template(system_template)
            instance_msg = self._render_template(instance_template, task=problem_statement)

            # Add initial messages to history
            ep.messages.append({"role": "system", "content": system_msg, "timestamp": time.time()})
            ep.messages.append({"role": "user", "content": instance_msg, "timestamp": time.time()})

            # Store episode
            self._episodes[episode_id] = ep

            # Build initial observation
            observation = f"{system_msg}\n\n{instance_msg}"

            return OpenEnvResponse(
                observation=observation,
                episode_id=episode_id,
                info=self._info(ep),
            )

        except ValueError as e:
            # Task not found
            return OpenEnvResponse(
                observation=f"Error: {str(e)}",
                done=True,
                truncated=True,
                info=self._info(None, error={"type": "task_not_found", "message": str(e), "retryable": False}),
            )
        except Exception as e:
            import traceback
            return OpenEnvResponse(
                observation=f"Error initializing episode: {str(e)}",
                done=True,
                truncated=True,
                info=self._info(None, error={"type": "init_error", "message": traceback.format_exc(), "retryable": True}),
            )

    async def step(
        self,
        action: str,
        episode_id: Optional[str] = None,
    ) -> OpenEnvResponse:
        """
        Execute an action in the current episode.

        Args:
            action: LLM's response containing THOUGHT + ```bash ... ``` (same format as minisweagent)
            episode_id: Episode identifier

        Returns:
            OpenEnvResponse with observation, reward, done status
        """
        # Validate episode_id
        if not episode_id:
            return OpenEnvResponse(
                observation="No episode_id provided. Call reset() first.",
                done=True,
                truncated=True,
                info=self._info(None, error={"type": "no_episode_id", "message": "episode_id is required", "retryable": True}),
            )

        ep = self._episodes.get(episode_id)
        if not ep:
            return OpenEnvResponse(
                observation=f"Episode {episode_id} not found. Call reset() first.",
                episode_id=episode_id,
                done=True,
                truncated=True,
                info=self._info(None, error={"type": "episode_not_found", "message": f"Episode {episode_id} not found", "retryable": True}),
            )

        if ep.done:
            return OpenEnvResponse(
                observation="Episode already finished. Call reset() to start a new one.",
                episode_id=episode_id,
                done=True,
                info=self._info(ep, error={"type": "episode_done", "message": "Episode already finished", "retryable": True}),
            )

        # Check step limit
        if ep.step_limit > 0 and ep.step_count >= ep.step_limit:
            ep.done = True
            ep.truncated = True
            return OpenEnvResponse(
                observation=f"Step limit ({ep.step_limit}) exceeded.",
                episode_id=episode_id,
                done=True,
                truncated=True,
                info=self._info(ep, error={"type": "step_limit_exceeded", "message": f"Exceeded {ep.step_limit} steps", "retryable": False}),
            )

        # Add assistant message to history
        ep.messages.append({"role": "assistant", "content": action, "timestamp": time.time()})

        # Count this step (same as minisweagent counting LLM calls via model.n_calls)
        ep.step_count += 1

        # Parse action to extract bash command
        bash_cmd = self._parse_action(action)
        if bash_cmd is None:
            # Format error - return error message (same as minisweagent)
            format_error_template = self._agent_config.get(
                "format_error_template",
                "Please always provide EXACTLY ONE action in triple backticks."
            )
            actions = re.findall(ACTION_REGEX, action, re.DOTALL)
            error_msg = self._render_template(format_error_template, actions=actions)
            ep.messages.append({"role": "user", "content": error_msg, "timestamp": time.time()})

            return OpenEnvResponse(
                observation=error_msg,
                episode_id=episode_id,
                info=self._info(ep, error={"type": "format_error", "message": "Invalid action format", "retryable": True}),
            )

        # Execute command in container
        try:
            output = self._execute_in_container(ep.container_id, bash_cmd, timeout=ep.command_timeout)
        except Exception as e:
            # Execution error
            error_msg = f"Command execution failed: {str(e)}"
            ep.messages.append({"role": "user", "content": error_msg, "timestamp": time.time()})
            return OpenEnvResponse(
                observation=error_msg,
                episode_id=episode_id,
                info=self._info(ep, error={"type": "execution_error", "message": str(e), "retryable": True}),
            )

        # Handle timeout
        if output.get("timeout"):
            timeout_template = self._agent_config.get(
                "timeout_template",
                "The last command timed out. Please try another command."
            )
            timeout_msg = self._render_template(
                timeout_template,
                action={"action": bash_cmd},
                output=output.get("output", "")
            )
            ep.messages.append({"role": "user", "content": timeout_msg, "timestamp": time.time()})
            return OpenEnvResponse(
                observation=timeout_msg,
                episode_id=episode_id,
                info=self._info(ep, error={"type": "command_timeout", "message": "Command timed out", "retryable": True}),
            )

        # Check if submitted (same as minisweagent: output starts with COMPLETE_TASK_AND_SUBMIT_FINAL_OUTPUT)
        output_text = output.get("output", "")
        lines = output_text.lstrip().splitlines(keepends=True)

        if lines and lines[0].strip() in ["MINI_SWE_AGENT_FINAL_OUTPUT", SUBMIT_MARKER]:
            if output.get("returncode", 0) != 0:
                # Command failed - let agent see error and retry
                pass
            else:
                # Submission successful - extract diff and verify
                ep.done = True

                # Extract submitted content (everything after the marker)
                submitted_content = "".join(lines[1:])
                ep.submitted_patch = submitted_content

                # Extract actual diff from container
                fix_patch = self._extract_diff_from_container(ep.container_id)

                # Verify fix
                score, test_stats = self._verify_fix(ep.bug_instance, fix_patch)

                # Build final observation
                final_observation = f"Submitted.\n\nFix patch:\n{fix_patch[:2000]}{'...(truncated)' if len(fix_patch) > 2000 else ''}"

                # Add test results to info
                info = self._info(ep)
                info["test_stats"] = test_stats
                info["fix_patch"] = fix_patch
                info["conversation"] = ep.messages

                return OpenEnvResponse(
                    observation=final_observation,
                    episode_id=episode_id,
                    reward=score,
                    done=True,
                    info=info,
                )

        # Normal step - format observation (same as minisweagent)
        action_observation_template = self._agent_config.get(
            "action_observation_template",
            "<returncode>{{output.returncode}}</returncode>\n<output>\n{{output.output}}</output>"
        )
        observation = self._render_template(action_observation_template, output=output)
        ep.messages.append({"role": "user", "content": observation, "timestamp": time.time()})

        return OpenEnvResponse(
            observation=observation,
            episode_id=episode_id,
            info=self._info(ep),
        )

    async def state(
        self,
        episode_id: Optional[str] = None,
    ) -> OpenEnvResponse:
        """
        Get current episode state without advancing.

        Args:
            episode_id: Episode identifier

        Returns:
            OpenEnvResponse with current observation
        """
        if not episode_id:
            return OpenEnvResponse(
                observation="No episode_id provided.",
                done=True,
                truncated=True,
                info=self._info(None, error={"type": "no_episode_id", "retryable": True}),
            )

        ep = self._episodes.get(episode_id)
        if not ep:
            return OpenEnvResponse(
                observation=f"Episode {episode_id} not found.",
                episode_id=episode_id,
                done=True,
                truncated=True,
                info=self._info(None, error={"type": "episode_not_found", "retryable": True}),
            )

        # Get current git status/diff
        status_result = self._execute_in_container(ep.container_id, "cd /app && git status --short", timeout=30)
        diff_result = self._execute_in_container(ep.container_id, "cd /app && git diff --stat", timeout=30)

        observation = f"Episode state:\n- Steps: {ep.step_count}/{ep.step_limit}\n- Done: {ep.done}\n\nGit status:\n{status_result.get('output', '')}\n\nGit diff stat:\n{diff_result.get('output', '')}"

        return OpenEnvResponse(
            observation=observation,
            episode_id=episode_id,
            done=ep.done,
            truncated=ep.truncated,
            info=self._info(ep),
        )

    async def stop(
        self,
        episode_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Stop and cleanup an episode.

        Args:
            episode_id: Episode identifier

        Returns:
            Status dictionary
        """
        if not episode_id:
            return {"status": "ok", "stopped": False, "message": "No episode_id provided"}

        ep = self._episodes.pop(episode_id, None)
        if not ep:
            return {"status": "ok", "stopped": False, "message": f"Episode {episode_id} not found"}

        # Stop container
        self._stop_container(ep.container_id)

        return {
            "status": "ok",
            "stopped": True,
            "episode_id": episode_id,
            "step_count": ep.step_count,
            "done": ep.done,
        }

    # ========== Original Evaluation Interface ==========

    async def evaluate(
        self,
        task_id: int,
        # Fixer model config
        model: str = "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8-TEE",
        base_url: str = "https://llm.chutes.ai/v1",
        api_key: Optional[str] = None,
        # Agent type selection
        fixer_agent: AgentType = "miniswe",
        # Common execution config
        timeout: int = 1800,
        temperature: float = 0.0,
        seed: Optional[int] = None,
        max_iterations: int = 100,
        cost_limit: float = 10.0,
    ) -> Dict[str, Any]:
        """
        Evaluate a fixer model on a pre-generated task.

        Tasks must be pre-generated by the breaker service and stored in R2.

        Args:
            task_id: Task ID (must exist in R2)
            model: Model for fixing bugs
            base_url: API base URL
            api_key: API key (uses env var CHUTES_API_KEY if not provided)
            fixer_agent: Agent type for bug fixing ("miniswe", "ridge")
            timeout: Timeout for commands
            temperature: Model temperature for fixer
            seed: Random seed for LLM inference
            max_iterations: Max agent steps for fixer
            cost_limit: Max cost for fixer

        Returns:
            Result dict with score and metadata

        Raises:
            ValueError: If task not found in R2
        """
        start = time.time()

        # Use provided api_key or fall back to instance api_key
        fixer_api_key = api_key or self.api_key
        if not fixer_api_key:
            raise ValueError("api_key required (pass to evaluate() or set CHUTES_API_KEY env var)")

        # Load pre-generated task from R2
        bug_instance = self._load_task(task_id)
        print(f"Loaded task {task_id}: {bug_instance['source']['swe_instance_id']}")

        # Fix bug using selected agent
        print(f"Fixing bug with {model} using {fixer_agent} agent...")

        # Get Docker image for the bug instance
        source = bug_instance["source"]
        instance_id = source["swe_instance_id"]
        repo = source["repo"]
        docker_image = get_dockerhub_image_uri(instance_id, self.dockerhub_username, repo)

        # Create fixer config
        fixer_config = FixerConfig(
            model=model,
            api_base=base_url,
            api_key=fixer_api_key,
            temperature=temperature,
            max_iterations=max_iterations,
            cost_limit=cost_limit,
            timeout=timeout,
            seed=seed,
        )

        # Create and run fixer agent
        agent = create_fixer_agent(fixer_agent, fixer_config)
        problem_statement = bug_instance["bug"]["problem_statement"]

        # Get patches needed to prepare buggy code state
        gold_patch = bug_instance["original"].get("gold_patch", "")
        bug_patch = bug_instance["bug"].get("patch", "")
        base_commit = source.get("base_commit", "")

        try:
            result = await agent.fix(
                problem_statement=problem_statement,
                docker_image=docker_image,
                gold_patch=gold_patch,
                bug_patch=bug_patch,
                base_commit=base_commit,
            )
            fix_patch = result.patch
            fixer_metadata = {
                "model_calls": result.model_calls,
                "model_cost": result.model_cost,
            }
            if result.error:
                fixer_metadata["fixer_error"] = result.error
            conversation = result.conversation or []
            # Build usage dict (matching openspiel format)
            usage = {
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "total_tokens": result.total_tokens,
            }
        finally:
            agent.cleanup()

        # Verify fix
        print("Verifying fix...")
        if not fix_patch or not fix_patch.strip():
            # Distinguish between infrastructure errors vs model failures
            # Following openspiel pattern:
            # - Infrastructure errors (timeout, API, docker): set error field (invalid sample, can retry)
            # - Model completed but no patch: no error field (valid sample, model just failed)
            if result.error:
                # Print full error for debugging
                print(f"[SWE-SYNTH] Fixer error occurred:\n{result.error}")

                error_msg = result.error.lower()
                if "timeout" in error_msg or "timed out" in error_msg:
                    error_type = "fixer_timeout"
                elif "api" in error_msg or "authentication" in error_msg or "connection" in error_msg or "network" in error_msg:
                    error_type = "api_error"
                elif "docker" in error_msg or "container" in error_msg:
                    error_type = "docker_error"
                else:
                    error_type = "fixer_error"

                print(f"[SWE-SYNTH] Classified as: {error_type}")
                test_stats = {"error": result.error, "error_type": error_type}
            else:
                # Model completed execution but didn't generate a valid patch
                # This is a valid sample - model just couldn't solve the problem
                # No error field = valid sample with score 0
                print("[SWE-SYNTH] No patch generated (model completed but produced no output)")
                test_stats = {"failure_reason": "no_patch_generated"}
            score = 0.0
        else:
            score, test_stats = self._verify_fix(bug_instance, fix_patch)

        # Get bug types from bug_instance
        bug_types = bug_instance.get("bug", {}).get("bug_types", [])

        result = {
            "task_name": "swe-synth",
            "score": score,
            "success": score > 0.0,
            "time_taken": time.time() - start,
            "extra": {
                # Task identification
                "task_id": task_id,
                "task_type": "swe-synth",
                "swe_instance_id": instance_id,
                "bug_types": bug_types,
                # Problem and solution
                "problem_statement": problem_statement,
                "fix_patch": fix_patch or "",
                # Interaction trajectory (matching openspiel format)
                "conversation": conversation,
                "usage": usage,
                # Fixer metadata
                **fixer_metadata,
                # Test results
                **test_stats,
            }
        }

        return result


# Alias for framework compatibility
Actor = SynthActor
